{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33862981",
   "metadata": {},
   "source": [
    "# Import libraries and declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4dc25f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from skimage.feature import local_binary_pattern\n",
    "import matplotlib.pyplot as plt\n",
    "from curvelops import FDCT2D\n",
    "from curvelops.plot import curveshow\n",
    "from skimage import io, color\n",
    "import pandas as pd\n",
    "from scipy.signal import cwt, ricker\n",
    "import multiprocessing\n",
    "import cv2\n",
    "\n",
    "convoluted_path = '/home/rajdeep/projects/image_segmentation/data/convoluted/'\n",
    "path_to_groundtruth = './GroundTruth.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f47ba",
   "metadata": {},
   "source": [
    "# Function for extracting LBP from FDCT of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c7ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdct_lbp(path):\n",
    "    image_array = cv2.imread(path)\n",
    "    #image = Image.open(path)\n",
    "    #image_array = np.array(image)\n",
    "    \n",
    "    \n",
    "    image_array = image_array.astype(float)\n",
    "    image_array /= 255.0\n",
    "    logo = image_array\n",
    "    C2D  = FDCT2D(image_array.shape[:-1], nbscales=4, nbangles_coarse=16, allcurvelets=False)\n",
    "    #coefficients = C2D.struct(C2D @ image_array)\n",
    "    # Parameters for LBP\n",
    "    subband = []\n",
    "    logo_r = C2D.struct(C2D @ image_array[..., 0])\n",
    "    logo_g = C2D.struct(C2D @ image_array[..., 1])\n",
    "    logo_b = C2D.struct(C2D @ image_array[..., 2])\n",
    "\n",
    "    # Concatenate the curvelet coefficients for each wedge\n",
    "    logo_c = [[] for _ in logo_r]\n",
    "    for iscale, c_angles in enumerate(logo_r):\n",
    "        logo_c[iscale] = []\n",
    "        for iwedge, c_wedge in enumerate(c_angles):\n",
    "            wedges = [\n",
    "                c[iscale][iwedge][..., np.newaxis].real\n",
    "                for c in [logo_r, logo_g, logo_b]\n",
    "            ]\n",
    "            out = np.concatenate(wedges, axis=-1)\n",
    "            # Rescaling because the curvelet coefficients are stronger than\n",
    "            # the original signal due to the FFT normalization\n",
    "            out *= np.sqrt(logo_r[iscale][iwedge].size / logo[..., 0].size)\n",
    "\n",
    "            # However, the above scaling may put the signal outside of the [0, 1]\n",
    "            # interval required for RGB images. As such we will rescale - purely\n",
    "            # for visualization purposes, values between 0 and 1.\n",
    "            out = (out - out.min()) / (out.max() - out.min())\n",
    "            logo_c[iscale].append(out)\n",
    "            subband.append(out)\n",
    "    # Apply LBP to each curvelet coefficient\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "\n",
    "    # Initialize a list to store LBP patterns\n",
    "    lbp_patterns = []\n",
    "\n",
    "    for coef in subband:\n",
    "        #print(coef.shape)\n",
    "        #image = color.rgb2gray(coef)\n",
    "        lbp = local_binary_pattern(coef[0], n_points, radius, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        lbp_patterns.append(hist)\n",
    "    aggregated_features = np.concatenate(lbp_patterns)\n",
    "    return aggregated_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ad5d0",
   "metadata": {},
   "source": [
    "# Perfrom FDCT and extract LBP from images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f885819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajdeep/projects/en/lib/python3.10/site-packages/skimage/feature/texture.py:353: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_groundtruth)\n",
    "\n",
    "\n",
    "columns = ['MEL','NV','BCC','AKIEC','DF','VASC']\n",
    "class_metadata = {} \n",
    "class_col = []\n",
    "data_col = []\n",
    "for col in columns:\n",
    "    \n",
    "    imgs = df[df.loc[:,col]==1]['image']\n",
    "    imgs = map(lambda x:convoluted_path + x + '.jpg',imgs)\n",
    "    category = col\n",
    "    one_hot_encoded = df[df.loc[:,col]==1].loc[:,columns].values\n",
    "    print(one_hot_encoded.shape)\n",
    "    class_metadata[category] = one_hot_encoded[0] \n",
    "    with multiprocessing.Pool(processes=16) as pool:\n",
    "        res = pool.map(fdct_lbp, imgs)\n",
    "        data_col.append(res)\n",
    "        class_col.append(one_hot_encoded)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf4456",
   "metadata": {},
   "source": [
    "# Save all the LBP features to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1419c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 500)\n",
      "(1, 1)\n",
      "Dictionary saved as a pickled file.\n",
      "Loaded dictionary: dict_keys(['class_metadata', 'features', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "data_card = {}\n",
    "data_card['class_metadata'] = class_metadata\n",
    "data_card['features'] = np.concatenate(data_col)\n",
    "data_card['labels'] = np.concatenate(class_col)\n",
    "print(data_card['features'].shape)\n",
    "print(data_card['labels'].shape)\n",
    "# File path to save the pickled dictionary\n",
    "file_path = \"./fdct_lbp.pkl\"\n",
    "\n",
    "# Save the dictionary as a pickled file\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(data_card, file)\n",
    "\n",
    "print(\"Dictionary saved as a pickled file.\")\n",
    "\n",
    "\n",
    "# Load the pickled dictionary\n",
    "with open(file_path, \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    print(\"Loaded dictionary:\", loaded_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
